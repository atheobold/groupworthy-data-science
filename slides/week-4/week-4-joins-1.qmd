---
title: "Data Joins + Pivots"
format: 
  revealjs:
        theme: [simple, ../style.scss]
editor: source
---

```{r}
#| include: false
#| message: false
#| label: setup

library(tidyverse)
library(palmerpenguins)
library(ggridges)
library(readxl)
```

## Tuesday, October 15

Today we will discuss...

-   Discord & Tokens
-   Grade Expectations 
    + Survey on Canvas
-   New Material
    -   Pivoting data with `tidyr`
    -   Joining data with `dplyr`
-   [PA 4: Military Spending](../../group-activities/week-4/PA4-tidyr.qmd)

# Discord & Deadline Extension Tokens

# Discord & Deadline Extension Tokens

> If you answer / respond to another student's question on Discord, you will 
> earn one additional "token" (3-day deadline extension request). 

# Grade Expectations

# Grade Expectations

> The [course syllabus](../../course-materials/course-syllabus.qmd#sec-grades)
> has been updated to reflect the grade criteria you all proposed. 

# Grade Expectations

> The [course syllabus](../../course-materials/course-syllabus.qmd#sec-grades)
> has been updated to reflect the grade criteria you all proposed. 

You have until Sunday [to vote]() 
on whether you agree with the proposed criteria, and to suggest ways these
criteria could be revised.


<!-- THE WARM-UP SHOULD MOVE TO INCLUDE THE READ EXCEL EXPLORATION -->

<!-- THE FOLLOW-UP SHOULD TALK ABOUT SEMI JOINS & PIVOTING -->

# Data Layouts

## Tidy Data

Tidy data...

-   is rectangular.
-   has observations as rows and variables as columns.
-   **has different formats for different tasks.**

![](https://r4ds.hadley.nz/images/tidy-1.png){fig-alt="This image shows a visual representation of the three key concepts in tidy data: variables, observations, and values. It is divided into three sections. The first section on the left highlights vertical arrows pointing down each column of a table, labeled 'variables,' showing that each column represents a different variable (country, year, cases, population). The middle section has horizontal arrows pointing across rows of the same table, labeled 'observations,' indicating that each row is an observation or data point. The third section on the right has circles around individual data points within the table, labeled 'values,' indicating the actual values for each variable in the dataset."}

## Creating Tidy Data

We may need to **transform** our data to turn it into the **version of tidy** that is best for a task at hand.

![Image by Allison Horst](https://www.openscapes.org/img/blog/tidydata/tidydata_4.jpg){fig-alt="An illustration of two round, fluffy characters, one green and one purple, holding a large table between them labeled 'TIDY.' The table is held by clamps on either side labeled 'WRANGLE' in orange and pink. The green character on the left is smiling with one arm raised, while the purple character on the right is cheering with both arms up. The table represents tidy data, and the clamps labeled 'WRANGLE' suggest data manipulation or preparation."}
## Military Expenditures

We will be using data from the Stockholm International Peace Research Institute
(SIPRI). The SIPRI Military Expenditure Database is an open source data set
containing time series on the military spending of countries from 1949--2019. 
The database is updated annually, which may include updates to data from
previous years.

Military expenditure is presented in many ways:

+ in local currency and in US $ (both from 2018 and current);
+ in terms of financial years and calendar years;
+ as a share of GDP and per capita.

## A Messy Excel File

First, you should notice that there are ten different sheets included in the
dataset. We are interested in the sheet labeled *"Share of Govt. spending"*, 
which contains information about the share of all government spending that is
allocated to the military.

Next, you'll notice that there are notes about the data in the first six rows.
Ugh! Also notice that the last six rows are footnotes about the data. **Ugh**!

Rather than copying this one sheet into a new Excel file and deleting the first
and last few rows, let's learn something new about the `read_xlsx()` function!

## Exploring `read_xlsx()` Arguments

The `read_xlsx()` function has several useful arguments:

+ `sheet`: specify the name of the sheet that you want to use. The name must be
passed in as a string (in quotations)!
+ `skip`: specify the number of rows you want to skip *before* reading in the
data.
+ `n_max`: specify the maximum number of rows of data to read in.

## Declaring the Sheet

```{r}
#| label: read-in-military-data

military <- read_xlsx(here::here("data", 
                                 "gov_spending_per_capita.xlsx"), 
                      sheet = )
```

## Skipping the Notes at the Top

```{r}
#| label: read-in-military-data

military <- read_xlsx(here::here("data", 
                                 "gov_spending_per_capita.xlsx"), 
                      sheet = , 
                      skip  = )
```

## Skipping the Footnotes at the Bottom

```{r}
#| label: read-in-military-data

military <- read_xlsx(here::here("data", 
                                 "gov_spending_per_capita.xlsx"), 
                      sheet = , 
                      skip  = , 
                      n_max = )
```

## Missing Data

The availability of data varies considerably by country, but we note that data
is available from at least the late 1950s for a majority of countries that were
independent at the time. Estimates for regional military expenditure have been
extended backwards depending on availability of data, but no estimates for total
world military expenditure are available before 1988 due to the lack of data
from the Soviet Union.

## Finding the `NA` Values

## Declaring `NA` Values

```{r}
#| label: read-in-data-code-missing-values

military <- read_xlsx(here::here("data", 
                                 "gov_spending_per_capita.xlsx"), 
                      sheet = , 
                      skip  = , 
                      n_max = , 
                      na = c()
                      )
```

## Cereal Data 

```{r}
#| echo: true
#| eval: false
#| label: cereal-preview-code
#| code-line-numbers: false

library(liver)
data(cereal)
head(cereal)
```

```{r}
#| eval: true
#| echo: false
#| label: cereal-preview-table

library(liver)
data(cereal)

head(cereal) |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "450px") |> 
  kableExtra::kable_styling(font_size = 30)
```

## Creating Tidy Data

Let's say we want to plot how military expenditures have changed over time. 

. . .

Currently, the data are in a **wide** format -- a separate column for each
year. 

**Transforming** the data will make plotting easier.

# Pivoting Data

::: columns
::: column
![](https://github.com/gadenbuie/tidyexplain/raw/main/images/static/png/original-dfs-tidy.png){fig-alt="Two tables side by side, illustrating the difference between 'wide' and 'long' data formats. The left table labeled 'wide' has columns: 'id,' 'x,' 'y,' and 'z.' The 'id' column contains the values 1 and 2, and the 'x,' 'y,' and 'z' columns contain the values a, b, c, d, e, and f spread across the rows. The right table labeled 'long' has columns: 'id,' 'key,' and 'val.' The 'id' column has repeated values (1 and 2), the 'key' column contains 'x,' 'y,' and 'z,' and the 'val' column contains 'a' through 'f,' corresponding to the wide table but reorganized in a 'long' format."}
:::

::: column
![](https://github.com/gadenbuie/tidyexplain/raw/main/images/tidyr-pivoting.gif){fig-alt="A gif showing the visual transformation of the data pictured, going from the wide format to the long format. Above the image is the R code that would produce each data layout."}
:::
:::


## Manual Method

Consider daily rainfall observed in SLO in January 2023.

+ The data is in a human-friendly form (like a calendar).
+ Each week has a row, and each day has a column.

![[Data source](cesanluisobispo.ucanr.edu)](images/slo-rainfall.jpg){fig-alt="A spreadsheet displaying a table with days of the week as column headers (Sunday to Saturday) and weeks numbered 1 to 5 in the first column. The table contains numerical values corresponding to each day of the week for each week. Some cells contain 'NA,' indicating missing values, while other cells contain numerical values like 0.12, 0.27, 4.26, and so on. Several cells contain zeros, and a few cells are left empty."}

How would you **manually** convert this to **long format**?


## Manual Method: Steps

::: incremental
::: {.small}
0.  Keep the column `Week`.
1.  Create a new column `Day_of_Week`.
2.  Create a new column `Rainfall` (hold daily rainfall values).
3.  Now we have three columns -- move Sunday values over.
:::
:::
. . .

<center> 

![](images/pivot_rain1.png){width=25% fig-alt="A spreadsheet displaying a table with days of the week as column headers (Sunday to Saturday) and weeks numbered 1 to 5 in the first column. The table contains numerical values corresponding to each day of the week for each week. Some cells contain 'NA,' indicating missing values, while other cells contain numerical values like 0.12, 0.27, 4.26, and so on. Several cells contain zeros, and a few cells are left empty."}

</center> 


## Manual Method: Steps

::: {.small}
0.  Keep the column `Week`.
1.  Create a new column `Day_of_Week`.
2.  Create a new column `Rainfall` (hold daily rainfall values).
3.  Now we have three columns -- move Sunday values over.
4.  Duplicate `Week` 1-5 and copy Monday values over.
:::

<center> 

![](images/pivot_rain2.png){width=25% fig-alt="A table with three columns: 'Week,' 'Day_of_Week,' and 'Rainfall.' The 'Week' column contains numbers 1 to 5, while the 'Day_of_Week' column alternates between 'Sunday' and 'Monday.' The 'Rainfall' column lists numerical values for each week and day. For Sunday, the rainfall values are 0, 0.27, 0.34, 0, and 'NA' for weeks 1 through 5, respectively. For Monday, the rainfall values are 0.12, 4.26, 0.33, 0, and 'NA' for weeks 1 through 5, respectively."}
</center> 


## Manual Method: Steps

::: {.small}
0.  Keep the column `Week`.
1.  Create a new column `Day_of_Week`.
2.  Create a new column `Rainfall` (hold daily rainfall values).
3.  Now we have three columns -- move Sunday values over.
4.  Duplicate `Week` 1-5 and copy Monday values over.
5.  Duplicate `Week` 1-5 and copy Tuesday values over.
:::

## Manual Method: Steps

::: {.small}
0.  Keep the column `Week`.
1.  Create a new column `Day_of_Week`.
2.  Create a new column `Rainfall` (hold daily rainfall values).
3.  Now we have three columns -- move Sunday values over.
4.  Duplicate `Week` 1-5 and copy Monday values over.
5.  Duplicate `Week` 1-5 and copy Tuesday values over.
6.  Continue for the rest of the days of the week.
:::

## Computational Approach

![](images/slo-rainfall-sketch.png){fig-alt="A table showing rainfall data for each day of the week across five weeks, with annotations explaining how to reshape the data from wide to long format. The table has columns for 'Week,' followed by the days of the week (Sunday to Saturday), and contains numerical values representing rainfall. There are three color-coded annotations: the 'Week' column is highlighted in green, labeled 'key' with the note 'keep this column, but repeat it many times.' The day names (Sunday through Saturday) are highlighted in red with the note 'turn into new column: Day_of_Week (repeat day of week many times).' The data cells are highlighted in blue with the note 'turn into new column: Rainfall (values for each week # and day of week).'"}

We can use `pivot_longer()` to turn a **wide** dataset into a **long(er)** dataset.


## `pivot_longer()`

Take a **wide** dataset and turn it into a **long** dataset.

+ `cols` -- specify the columns that should be pivoted.
  + Do **not** include the names of ID columns (columns to not be pivoted).
+ `names_to` -- the name of the new column containing the old column names.
+ `values_to` -- the name of the new column containing the old  column values.


## `pivot_longer()`

```{r}
#| echo: true
#| eval: false
#| code-line-numbers: false
#| label: slo-rain-pivot-longer-code

slo_rainfall |> 
  pivot_longer(cols = Sunday:Saturday,
               names_to  = "Day_of_Week",
               values_to = "Daily_Rainfall")
```

```{r}
#| eval: true
#| echo: false
#| code-line-numbers: false
#| label: slo-rain-pivot-longer-table


slo_rainfall <- read_xlsx("data/2023-rainfall-slo.xlsx")

slo_rainfall |> 
  mutate(across(Sunday:Saturday, as.numeric)) |> 
  pivot_longer(cols      = Sunday:Saturday,
               names_to  = "Day_of_Week",
               values_to = "Daily_Rainfall")|> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "500px") |> 
  kableExtra::kable_styling(font_size = 30)
```


<!-- ## `pivot_wider()` -->

<!-- Take a **long** dataset and turn it into a **wide** dataset. -->

<!-- + `id_cols` -- specify the column(s) that contain the ID for unique rows in the wide dataset. -->
<!-- + `names_from` -- the name of the column containing the new column names. -->
<!-- + `values_from` -- the name of the column containing the new  column values. -->


<!-- ## `pivot_wider()` -->

<!-- Let's say we calculate the `mean` amount of `protein` for cereals on each `shelf` and for each `manuf`. -->

<!-- ```{r} -->
<!-- #| echo: true -->
<!-- #| eval: false -->
<!-- #| code-line-numbers: false -->
<!-- #| label: long-cereal-summary-code -->

<!-- mean_protein <- cereal |>  -->
<!--   group_by(manuf, shelf) |>  -->
<!--   summarize(mean_protein = mean(protein)) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- #| eval: true -->
<!-- #| echo: false -->
<!-- #| label: long-cereal-summary-table -->

<!-- mean_protein <- cereal |>  -->
<!--   group_by(manuf, shelf) |>  -->
<!--   summarize(mean_protein = mean(protein)) -->

<!-- mean_protein |>  -->
<!--   knitr::kable() |>  -->
<!--   kableExtra::scroll_box(height = "400px") |>  -->
<!--   kableExtra::kable_styling(font_size = 30) -->
<!-- ``` -->


<!-- ## `pivot_wider()` -->

<!-- We can make this dataset more easily readable... -->

<!-- . . . -->

<!-- ```{r} -->
<!-- #| eval: false -->
<!-- #| echo: true -->
<!-- #| label: pivot-summary-wider-code -->
<!-- #| code-line-numbers: false -->

<!-- mean_protein |>  -->
<!--   arrange(shelf) |>  -->
<!--   pivot_wider(id_cols = manuf, -->
<!--               names_from = shelf, -->
<!--               values_from = mean_protein) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- #| eval: true -->
<!-- #| echo: false -->
<!-- #| label: pivot-summary-wider-table -->
<!-- #| code-line-numbers: false -->

<!-- mean_protein |>  -->
<!--   arrange(shelf) |>  -->
<!--   pivot_wider(id_cols = manuf, -->
<!--               names_from = shelf, -->
<!--               values_from = mean_protein) |>  -->
<!--   knitr::kable() |>  -->
<!--   kableExtra::scroll_box(height = "420px") |>  -->
<!--   kableExtra::kable_styling(font_size = 30) -->
<!-- ``` -->


<!-- ## Better names in `pivot_wider()` -->

<!-- ```{r} -->
<!-- #| eval: false -->
<!-- #| echo: true -->
<!-- #| code-line-numbers: "6" -->
<!-- #| label: add-fancy-name-code -->

<!-- mean_protein |>  -->
<!--   arrange(shelf) |>  -->
<!--   pivot_wider(id_cols = manuf, -->
<!--               names_from = shelf, -->
<!--               values_from = mean_protein, -->
<!--               names_prefix = "Shelf_") -->
<!-- ``` -->

<!-- ```{r} -->
<!-- #| eval: true -->
<!-- #| echo: false -->
<!-- #| label: add-fancy-name-table -->

<!-- mean_protein |>  -->
<!--   arrange(shelf) |>  -->
<!--   pivot_wider(id_cols = manuf, -->
<!--               names_from = shelf, -->
<!--               values_from = mean_protein, -->
<!--               names_prefix = "Shelf_") |>  -->
<!--   knitr::kable() |>  -->
<!--   kableExtra::scroll_box(height = "420px") |>  -->
<!--   kableExtra::kable_styling(font_size = 30) -->
<!-- ``` -->


# Data Joins

## Data Joins

We can **combine** (join) data tables based on their relations.

::: columns
::: {.column width="50%"}
**Mutating joins**

Add *variables* from a new dataframe to observations in an existing dataframe.

`full_join()`, `left_join()`, `right_join()`, `inner_join()`
:::

::: {.column width="5%"}
:::

::: {.column width="45%"}
**Filtering Joins**

Filter *observations* based on values in new dataframe.

`semi_join()`, `anti_join()`
:::
:::

## Keys

A key uniquely identifies an observation in a data set.

+ To combine (join) two datasets, the **key** needs to be present in both.

. . .

![](images/imdb-keys.png){fig-alt="A similar entity-relationship diagram (ERD) to the previous one, with the same tables and relationships between movie-related data. However, in this version, key columns in the tables are color-coded to highlight relationships. Orange highlights the 'director_id' in the 'directors_genres,' 'movies_directors,' and 'directors' tables, showing the connection between directors and their genres and movies. Blue highlights the 'movie_id' in the 'movies_directors,' 'movies_genres,' 'roles,' and 'movies' tables, showing the relationship between movies, genres, and roles. Green highlights the 'actor_id' in the 'roles' and 'actors' tables, showing the connection between actors and their roles in movies. Arrows continue to represent relationships between tables, following foreign key connections, now emphasized with the color coding."}


## Filtering Joins: `semi_join()`

Keeps observations when their keys are present in **both** datasets,
**but only keeps variables from the first dataset**.

![© Garrick Aden-Buie](https://github.com/gadenbuie/tidyexplain/raw/main/images/semi-join.gif){fig-alt="A looping animation shows two tables side by side and the result of a semi join. The left table (x) has keys 1 (red), 2 (blue), 3 (green) paired with x1, x2, x3. The right table (y) has keys 1 (red), 2 (blue), 4 (purple) paired with y1, y2, y4. Matching key rows (1 and 2) are connected. The resulting output table includes only the rows from the left table that have matches in the right table: key 1 with x1 and key 2 with x2. The left row with key 3 is dropped, and no new columns from y are shown."}

<!-- :::: {.columns} -->
<!-- ::: {.column width="60%"} -->

<!-- ![](images/semi1.png){fig-alt="An illustration of a semi join between two tables, each with two columns. The table labeled 'x,' has a key column with values 1, 2, and 3 and a value column with 'x1,' 'x2,' and 'x3.' The table labeled 'y,' has a key column with values 1, 2, and 4 and a value column with 'y1,' 'y2,' and 'y4.'"} -->
<!-- ::: -->
<!-- ::: {.column width="15%"} -->

<!-- <br> -->

<!-- ::: {.r-fit-text} -->
<!-- &rarr; &emsp; -->
<!-- ::: -->

<!-- ::: -->
<!-- ::: {.column width="25%"} -->

<!-- ![](images/semi2.png){fig-alt="An arrow points from the first two tables (x and y) toward the right where a single table is displayed. This table is the result of a semi join, where only the values of x that had a match in y are kept. The resulting table includes rows with matching key values from both 'x' and 'y' (keys 1 and 2), displaying only the 'x' values ('x1' and 'x2'). Rows with non-matching keys (3 and 4) are excluded."} -->

<!-- ::: -->
<!-- :::: -->


## Filtering Joins: `semi_join()`

::: panel-tabset

### `semi_join()`

```{r}
#| echo: true
#| eval: false
#| code-line-numbers: false

directors_genres |> 
  semi_join(movies_directors)
```

```{r}
#| eval: true
#| echo: false
semi_join(directors_genres_subset, movies_directors_subset) |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "320px") |> 
  kableExtra::kable_styling(font_size = 30)
```

Movie Directors: 429, ~~**2931**~~, 11652, 14927, 15092

### Connection to `filter()`

```{r}
#| echo: true
#| eval: false
#| code-line-numbers: false
directors_genres |>
  filter(director_id %in% movies_directors$director_id)
```

```{r}
#| eval: true
#| echo: false
directors_genres_subset |>
  filter(director_id %in% movies_directors_subset$director_id) |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "320px") |> 
  kableExtra::kable_styling(font_size = 30)
```

:::


## Filtering Joins: `anti_join()`

**Removes** observations when their keys are present in **both** datasets, and **only keeps variables from the first dataset**.

![© Garrick Aden-Buie](https://github.com/gadenbuie/tidyexplain/raw/main/images/anti-join.gif){fig-alt="A looping animation shows two tables being compared under an ‘anti join’ operation. The left table has keys 1 (red), 2 (blue), 3 (green) paired with values x1, x2, x3. The right table has keys 1 (red), 2 (blue), and 4 (purple) paired with values y1, y2, y4. Lines indicate matching keys (1 and 2). The resulting table on the right contains only the rows from the left table that do not have a match in the right: key 3 with x3 (green). Keys 1 and 2 are excluded because they have matches in the right table."}

<!-- :::: {.columns} -->
<!-- ::: {.column width="60%"} -->

<!-- ![](images/semi1.png){fig-alt="Two tables on the left labeled 'x' and 'y,' each with two columns, show key-value pairs. The 'x' table contains a key column with values 1, 2, and 3 and a value column with 'x1,' 'x2,' and 'x3.' The 'y' table contains a key column with values 1, 2, and 4 and a value column with 'y1,' 'y2,' and 'y4.'"} -->
<!-- ::: -->
<!-- ::: {.column width="15%"} -->

<!-- <br> -->

<!-- ::: {.r-fit-text} -->
<!-- &rarr; &emsp; -->
<!-- ::: -->

<!-- ::: -->
<!-- ::: {.column width="25%"} -->

<!-- <br> -->

<!-- ![](images/anti2.png){fi-alt="An arrow points to the right, showing the result of an anti join. The resulting table includes the row from 'x' where the key (3) does not have a corresponding match in 'y.' It contains only the key-value pair (3, x3), demonstrating that the anti join keeps only the unmatched rows from the left table ('x')."} -->

<!-- ::: -->
<!-- :::: -->


## Filtering Joins: `anti_join()`

::: panel-tabset

### `anti_join()`

```{r}
#| echo: true
#| eval: false
#| code-line-numbers: false

directors_genres |> 
  anti_join(movies_directors)
```

```{r}
#| eval: true
#| echo: false
anti_join(directors_genres_subset, movies_directors_subset) |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "200px") |> 
  kableExtra::kable_styling(font_size = 30)
```

Movie Directors: ~~429~~, **2931**, ~~11652~~, ~~14927~~, ~~15092~~

### Connection to `filter()`

```{r}
#| echo: true
#| eval: false
#| code-line-numbers: false

directors_genres |>
  filter(!director_id %in% movies_directors$director_id)
```

```{r}
#| eval: true
#| echo: false
directors_genres_subset |>
  filter(!director_id %in% movies_directors_subset$director_id) |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "200px") |> 
  kableExtra::kable_styling(font_size = 30)
```

:::


## [PA 4: Military Spending](../../group-activities/week-4/PA-4-tidyr.qmd)

Today you will be tidying messy data to explore the relationship between countries of the world and military spending.

## This activity will require knowledge of:

::: columns
::: {.column width="60%"}
::: {.small}
- function documentation
- function arguments
- locating missing values
- character vectors
- keys joining two datasets
- searching / iterating over multiple columns
- pivoting data from wide to long
- creating side-by-side boxplots
- locating the median on a boxplot
- estimating the variability from a boxplot
:::
:::

::: {.column width="5%"}
:::

::: {.column width="35%"}
[**None of us have all these abilities. Each of us has some of these abilities.**]{.midi}

:::
:::

## dplyr Resources

::: columns
::: {.column width="60%"}
Every group should have a **dplyr** cheatsheet!

**On the Back**: The Combine Tables section gives advice on joining two datasets

- The "Filtering Join" section will be helpful when performing an `anti_join()`!
:::

::: {.column width="5%"}
:::

::: {.column width="35%"}
![](images/dplyr-cheatsheet-back.png){fig-alt="A picture of the dplyr cheatsheet, which contains helpful information on working with data in a variety of ways."}
:::
:::

## tidyr Resources

::: columns
::: {.column width="60%"}
Every group should have a **tidyr** cheatsheet!

**On the Front**: The Reshape Data section gives advice on pivoting a dataset
from wide to long
:::

::: {.column width="5%"}
:::

::: {.column width="35%"}
![](images/tidyr-cheatsheet.png){fig-alt="A picture of the tidyr cheatsheet, which contains helpful information on transforming data in a variety of ways."}

:::
:::

## Task Card

Every group should have a **task card**! 

. . .

::: columns
::: {.column width="40%"}
**On the Front**

- the expectations of each role
- the norms of collaborating
:::

::: {.column width="5%"}
:::

::: {.column width="55%"}
::: {.fragment}
**On the Back**

- code and pictures for performing an `anti_join()`
- code and pictures for pivoting a dataset from wide to long
- guidelines for formatting `dplyr` and `tidyr` code
:::
:::
:::

## Pair Programming Expectations

::: columns
::: {.column width="49%"}
**Developer**

::: {.small}
-   Reads prompt and ensures Coder understands what is being asked. 
-   Types the code specified by the Coder into the Quarto document.
-   Runs the code provided by the Coder. 
-   Works with Coder to debug the code. 
-   Evaluates the output.  
-   Works with Coder to write code comments. 
:::
:::

::: {.column width="2%"}
:::

::: {.column width="49%"}
::: {.fragment}
**Coder**

::: {.small}
-   Reads out instructions or prompts
-   Directs the Developer what to type. 
-   Talks with Developer about their ideas. 
-   Manages resources (e.g., cheatsheets, textbook, slides). 
-   Works with Developer to debug the code. 
-   Works with Developer to write code comments. 
:::
:::
:::
:::

## Getting Started

::: {.small}
First, both of you will do the following:

- Join your Practice Activity workspace in Posit Cloud
  * You are in a new group, so you should have a new workspace!
- Log-in to Posit Cloud
- Open the PA 4: Military Spending project
- Open the `PA4-dplyr.qmd` file
:::

. . .

::: {.small}
Then, the partner who woke up the earliest today starts as the Developer (typing
and listening to instructions from the Coder)!

- The Coder **does not type**. 
  * The collaborative editing feature should allow you to track what is being 
  typed. 
- The Developer **only types what they are told to type**. 
:::

## External Resources

During the Practice Activity, you **are not** permitted to use Google or ChatGPT
for help. 

. . .

</br> 

You **are** permitted to use:

- the `dplyr` cheatsheet,
- the `tidyr` cheatsheet, 
- the course textbook, and
- the course slides. 

## Submission

- Each person will input your responses to Canvas Questions 1, 2, and 3 into 
the PA4 Canvas quiz.
- The person who last occupied the role of Developer will download and submit
the `PA-4.html` file for the group.
  + Only one submission per group!

# Exit Ticket
