---
title: "Data Joins + Pivots + Factors"
format: 
  revealjs:
        theme: [simple, ../style.scss]
editor: source
---

```{r setup}
#| include: false
#| message: false
library(tidyverse)
library(palmerpenguins)
library(ggridges)
```

## Tuesday, October 15

Today we will...

-   Comments from Week 3
-   New Material
    -   Pivoting data with `tidyr`
    -   Joining data with `dplyr`
-   [PA 4: Military Spending](../../group-activities/week-4/PA4-tidyr.qmd)

# Data Layouts

## Tidy Data

Tidy data...

-   is rectangular.
-   has observations as rows and variables as columns.
-   **has different formats for different tasks.**

![](https://r4ds.hadley.nz/images/tidy-1.png)

## Creating Tidy Data

We may need to **transform** our data to turn it into the **version of tidy** that is best for a task at hand.

![Image by Allison Horst](https://www.openscapes.org/img/blog/tidydata/tidydata_4.jpg)

## Cereal Data 

```{r}
#| echo: true
#| eval: false
library(liver)
data(cereal)
head(cereal)
```

```{r}
#| eval: true
#| echo: false
library(liver)
data(cereal)
head(cereal) |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "210px") |> 
  kableExtra::kable_styling(font_size = 30)
```

## Creating Tidy Data

Let's say we want to look at `mean` **cereal nutrients** based on `shelf`.

. . .

Currently, the data are in a **wide** format -- a separate column for each
nutrient. **Transforming** the data will make plotting easier.

## Tidying the Cereals Data

::: panel-tabset

## Wide

```{r}
#| echo: true
#| code-line-numbers: "2-3"
#| code-fold: true
cereal_wide <- cereal |> 
  group_by(shelf) |> 
  summarise(across(calories:vitamins, mean))
```

```{r}
#| eval: true
#| echo: false
cereal_wide|> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "210px") |> 
  kableExtra::kable_styling(font_size = 30)
```

## Wide Plot

```{r}
#| echo: true
#| code-line-numbers: "5-8"
#| fig-height: 4
#| fig-width: 6
#| fig-align: center
#| code-fold: true
my_colors <- c("calories_col" = "steelblue", "sugars_col" = "orange3")

cereal_wide |> 
  ggplot() +
  geom_point(aes(x = shelf, y = calories, color = "calories_col")) +
  geom_line(aes(x = shelf, y = calories, color = "calories_col")) + 
  geom_point(aes(x = shelf, y = sugars, color = "sugars_col")) +
  geom_line(aes(x = shelf, y = sugars, color = "sugars_col")) +
  scale_color_manual(values = my_colors, labels = names(my_colors)) +
  labs(x = "Shelf", y = "", subtitle = "Mean Amount", color = "Nutrient")
```

## Long

```{r}
#| echo: true
#| code-line-numbers: "5-6"
#| code-fold: true
cereal_long<- cereal |> 
  pivot_longer(cols = calories:vitamins,
               names_to = "Nutrient",
               values_to = "Amount") |> 
  group_by(shelf, Nutrient) |> 
  summarise(mean_amount = mean(Amount))
```

```{r}
#| eval: true
#| echo: false
cereal_long |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "400px") |> 
  kableExtra::kable_styling(font_size = 30)
```

## Long Plot

```{r}
#| echo: true
#| code-line-numbers: "2-4"
#| fig-height: 4
#| fig-width: 6
#| fig-align: center
#| code-fold: true
cereal_long |> 
  ggplot(aes(x = shelf, 
             y = mean_amount, 
             color = Nutrient)) +
  geom_point() +
  geom_line() +
  labs(x = "Shelf", y = "", subtitle = "Mean Amount")
```
:::


# Pivoting Data

::: columns
::: column
![](https://github.com/gadenbuie/tidyexplain/raw/main/images/static/png/original-dfs-tidy.png)
:::

::: column
![](https://github.com/gadenbuie/tidyexplain/raw/main/images/tidyr-pivoting.gif)
:::
:::


## Manual Method

Consider daily rainfall observed in SLO in January 2023.

+ The data is in a human-friendly form (like a calendar).
+ Each week has a row, and each day has a column.

![[Data source](cesanluisobispo.ucanr.edu)](images/slo-rainfall.jpg)

How would you **manually** convert this to **long format**?


## Manual Method: Steps

::: incremental
::: {.small}
0.  Keep the column `Week`.
1.  Create a new column `Day_of_Week`.
2.  Create a new column `Rainfall` (hold daily rainfall values).
3.  Now we have three columns -- move Sunday values over.
:::
:::
. . .

<center> 

![](images/pivot_rain1.png){width=25%}

</center> 


## Manual Method: Steps

::: {.small}
0.  Keep the column `Week`.
1.  Create a new column `Day_of_Week`.
2.  Create a new column `Rainfall` (hold daily rainfall values).
3.  Now we have three columns -- move Sunday values over.
4.  Duplicate `Week` 1-5 and copy Monday values over.
:::

<center> 

![](images/pivot_rain2.png){width=25%}
</center> 


## Manual Method: Steps

::: {.small}
0.  Keep the column `Week`.
1.  Create a new column `Day_of_Week`.
2.  Create a new column `Rainfall` (hold daily rainfall values).
3.  Now we have three columns -- move Sunday values over.
4.  Duplicate `Week` 1-5 and copy Monday values over.
5.  Duplicate `Week` 1-5 and copy Tuesday values over.
:::

## Manual Method: Steps

::: {.small}
0.  Keep the column `Week`.
1.  Create a new column `Day_of_Week`.
2.  Create a new column `Rainfall` (hold daily rainfall values).
3.  Now we have three columns -- move Sunday values over.
4.  Duplicate `Week` 1-5 and copy Monday values over.
5.  Duplicate `Week` 1-5 and copy Tuesday values over.
6.  Continue for the rest of the days of the week.
:::

## Computational Approach

![](images/slo-rainfall-sketch.png)

We can use `pivot_longer()` to turn a **wide** dataset into a **long(er)** dataset.


## `pivot_longer()`

Take a **wide** dataset and turn it into a **long** dataset.

+ `cols` -- specify the columns that should be pivoted.
  + Do **not** include the names of ID columns (columns to not be pivoted).
+ `names_to` -- the name of the new column containing the old column names.
+ `values_to` -- the name of the new column containing the old  column values.


## `pivot_longer()`

```{r}
#| echo: true
#| eval: false
slo_rainfall |> 
  pivot_longer(cols = Sunday:Saturday,
               names_to  = "Day_of_Week",
               values_to = "Daily_Rainfall")
```

```{r}
#| eval: true
#| echo: false
library(readxl)
slo_rainfall <- read_xlsx("data/2023-rainfall-slo.xlsx")

slo_rainfall |> 
  mutate(across(Sunday:Saturday, as.numeric)) |> 
  pivot_longer(cols      = Sunday:Saturday,
               names_to  = "Day_of_Week",
               values_to = "Daily_Rainfall")|> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "500px") |> 
  kableExtra::kable_styling(font_size = 30)
```


## `pivot_wider()`

Take a **long** dataset and turn it into a **wide** dataset.

+ `id_cols` -- specify the column(s) that contain the ID for unique rows in the wide dataset.
+ `names_from` -- the name of the column containing the new column names.
+ `values_from` -- the name of the column containing the new  column values.


## `pivot_wider()`

Let's say we calculate the `mean` amount of `protein` for cereals on each `shelf` and for each `manuf`.

```{r}
#| echo: true
#| eval: false
mean_protein <- cereal |> 
  group_by(manuf, shelf) |> 
  summarize(mean_protein = mean(protein))
```

```{r}
#| eval: true
#| echo: false
mean_protein <- cereal |> 
  group_by(manuf, shelf) |> 
  summarize(mean_protein = mean(protein))

mean_protein |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "400px") |> 
  kableExtra::kable_styling(font_size = 30)
```


## `pivot_wider()`

We can make this dataset more easily readable...

. . .

```{r}
#| eval: false
#| echo: true
mean_protein |> 
  arrange(shelf) |> 
  pivot_wider(id_cols = manuf,
              names_from = shelf,
              values_from = mean_protein)
```

```{r}
#| eval: true
#| echo: false
mean_protein |> 
  arrange(shelf) |> 
  pivot_wider(id_cols = manuf,
              names_from = shelf,
              values_from = mean_protein) |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "420px") |> 
  kableExtra::kable_styling(font_size = 30)
```


## Better names in `pivot_wider()`


```{r}
#| eval: false
#| echo: true
#| code-line-numbers: "6"
mean_protein |> 
  arrange(shelf) |> 
  pivot_wider(id_cols = manuf,
              names_from = shelf,
              values_from = mean_protein,
              names_prefix = "Shelf_")
```

```{r}
#| eval: true
#| echo: false
mean_protein |> 
  arrange(shelf) |> 
  pivot_wider(id_cols = manuf,
              names_from = shelf,
              values_from = mean_protein,
              names_prefix = "Shelf_") |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "420px") |> 
  kableExtra::kable_styling(font_size = 30)
```


# Data Joins

## Relational Data

Multiple, interconnected tables of data are called **relational**.

+ It is the *relation* between datasets, not just the individual datasets themselves, that are important.

![IMDb movie relational data](images/imdb_relational.png)

```{r imdb-data}
#| eval: false
#| include: false
#| message: false
#| warning: false
library(RMariaDB)
library(dm)
`
# IMDb
con <- dbConnect(
  drv = RMariaDB::MariaDB(), 
  username = "guest",
  password = "relational", 
  host = "relational.fit.cvut.cz", 
  port = 3306,
  dbname = "imdb_small")
dbListTables(con)

my_dm <- dm_from_src(con)

actors <- my_dm$actors |> 
  as.data.frame()
write_csv(actors, "data/actors.csv", na = "")

directors <- my_dm$directors |> 
  as.data.frame()
write_csv(directors, "data/directors.csv", na = "")

directors_genres <- my_dm$directors_genres |> 
  as.data.frame()
write_csv(directors_genres, "data/directors_genres.csv", na = "")

movies <- my_dm$movies |> 
  as.data.frame()
write_csv(movies, "data/movies.csv", na = "")

movies_directors <- my_dm$movies_directors |> 
  as.data.frame()
write_csv(movies_directors, "data/movies_directors.csv", na = "")

movies_genres <- my_dm$movies_genres |> 
  as.data.frame()
write_csv(movies_genres, "data/movies_genres.csv", na = "")

roles <- my_dm$roles |> 
  as.data.frame()
write_csv(roles, "data/roles.csv", na = "")

dbDisconnect(con)
rm(con, my_dm)
```

```{r imdb-data2}
#| eval: true
#| include: false
#| message: false
#| warning: false

actors <- read_csv("data/actors.csv")
directors <- read_csv("data/directors.csv")
directors_genres <- read_csv("data/directors_genres.csv")
movies <- read_csv("data/movies.csv")
movies_directors <- read_csv("data/movies_directors.csv")
movies_genres <- read_csv("data/movies_genres.csv")
roles <- read_csv("data/roles.csv")
```


## Data Joins

We can **combine** (join) data tables based on their relations.

::: columns
::: column
**Mutating joins**

Add *variables* from a new dataframe to observations in an existing dataframe.

`full_join()`, `left_join()`, `right_join()`, `inner_join()`, `outer_join()`
:::

::: column
**Filtering Joins**

Filter *observations* based on values in new dataframe.

`semi_join()`, `anti_join()`
:::
:::


## Keys

A key uniquely identifies an observation in a data set.

+ To combine (join) two datasets, the **key** needs to be present in both.

. . .

![](images/imdb-keys.png)


## `inner_join()`

Keeps obsertvations when their keys are present in **both** datasets.

:::: {.columns}
::: {.column width="50%"}
![](images/join_xy.png)
:::
::: {.column width="50%"}
![](images/inner_join.png)

:::
::::


## `inner_join()`: IMDb Example

```{r}
directors_genres_subset <- directors_genres |>
  filter(director_id %in% c(429, 2931, 11652, 14927, 15092)) |> 
  group_by(director_id) |> 
  slice_max(order_by = prob, n = 2, with_ties = F)

movies_directors_subset <- movies_directors |> 
  filter(director_id %in% c(429, 9247, 11652, 14927, 15092))

directors_subset <- directors |> 
  filter(id %in% c(429, 9247, 11652, 14927, 15092))
```

:::: {.columns}
::: {.column width="50%"}

```{r}
#| eval: false
#| echo: true
#| code-line-numbers: false
directors_genres
```

```{r}
#| eval: true
#| echo: false
directors_genres_subset |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "160px") |> 
  kableExtra::kable_styling(font_size = 30)
```

:::
::: {.column width="50%"}

```{r}
#| eval: false
#| echo: true
#| code-line-numbers: false
movies_directors
```

```{r}
#| eval: true
#| echo: false
movies_directors_subset |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "160px") |> 
  kableExtra::kable_styling(font_size = 30)
```

:::
::::

<font size = 6>

ID: 429, **2931**, 11652, 14927, 15092  &emsp; &emsp; &ensp;  ID: 429, **9247**, 11652, 14927, 15092

</font>

. . .

```{r}
#| eval: false
#| echo: true
#| code-line-numbers: false
inner_join(directors_genres, movies_directors)
```

```{r}
#| eval: true
#| echo: false
inner_join(directors_genres_subset, movies_directors_subset) |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "160px") |> 
  kableExtra::kable_styling(font_size = 30)
```

<font size = 6>

ID: 429, ~~**2931**~~, ~~**9247**~~, 11652, 14927, 15092

</font>


## `inner_join()`: IMDb Example

What if our **key** does not have the same name?

:::: {.columns}
::: {.column width="50%"}

```{r}
#| eval: false
#| echo: true
#| code-line-numbers: false
directors_genres
```

```{r}
#| eval: true
#| echo: false
directors_genres_subset |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "170px") |> 
  kableExtra::kable_styling(font_size = 30)
```

:::
::: {.column width="50%"}

```{r}
#| eval: false
#| echo: true
#| code-line-numbers: false
directors
```

```{r}
#| eval: true
#| echo: false
directors_subset |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "170px") |> 
  kableExtra::kable_styling(font_size = 30)
```

:::
::::

. . .

:::: {.columns}
::: {.column width="60%"}

```{r}
#| eval: false
#| echo: true
#| code-line-numbers: "3"
inner_join(directors_genres, 
           directors, 
           join_by(director_id == id))
```

```{r}
#| eval: true
#| echo: false
inner_join(directors_subset,
           directors_genres_subset,
           join_by(id == director_id)) |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "170px") |> 
  kableExtra::kable_styling(font_size = 30)
```

:::
::: {.column width="40%"}
<font size = 6>
Join by different variables on `dataX` and `dataY`: `join_by(a == b)` will match `dataX$a` to `dataY$b`.

</font>
:::
::::

## Piping Joins

Remember: the dataset you pipe in becomes the **first argument** of the function you are piping into!

+ So if you are using a pipe, you will only be specifying the **right** dataset inside the `join` function.

. . .

```{r}
#| eval: false
#| echo: true
#| code-line-numbers: false
inner_join(directors_genres, movies_directors)
```

...is equivalent to...

```{r}
#| eval: false
#| echo: true
#| code-line-numbers: false
directors_genres |> 
  inner_join(movies_directors)
```



## More Mutating Joins

-   `left_join()` -- keep only (and all) observations present in the left data set

-   `right_join()` -- keep only (and all) observations present in the right data set 

-   `full_join()` -- keep only (and all) observations present in **both** data sets

<center>

![](images/joins.png){width=70%}

</center>


## More Mutating Joins

Which directors would **remain** for each of the following?

<font size = 6>

-   `left_join(directors_genres, movies_directors)`
-   `right_join(directors_genres, movies_directors)`
-   `full_join(directors_genres, movies_directors)`

</font>

::: columns
::: column
```{r}
#| eval: false
#| echo: true
directors_genres |> 
  distinct(director_id)
```

```{r}
#| eval: true
#| echo: false
directors_genres_subset |> 
  distinct(director_id) |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "320px") |> 
  kableExtra::kable_styling(font_size = 30)
```

:::

::: column
```{r}
#| eval: false
#| echo: true
movies_directors |> 
  distinct(director_id)
```

```{r}
#| eval: true
#| echo: false
movies_directors_subset |> 
  distinct(director_id) |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "320px") |> 
  kableExtra::kable_styling(font_size = 30)
```
:::
:::


## Filtering Joins: `semi_join()`

Keeps observations when their keys are present in **both** datasets, **but only keeps variables from the first dataset**.

:::: {.columns}
::: {.column width="60%"}

![](images/semi1.png)
:::
::: {.column width="15%"}

<br>

::: {.r-fit-text}
&rarr; &emsp;
:::

:::
::: {.column width="25%"}

![](images/semi2.png)

:::
::::


## Filtering Joins: `semi_join()`

::: panel-tabset

### `semi_join()`

```{r}
#| echo: true
#| eval: false
directors_genres |> 
  semi_join(movies_directors)
```

```{r}
#| eval: true
#| echo: false
semi_join(directors_genres_subset, movies_directors_subset) |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "320px") |> 
  kableExtra::kable_styling(font_size = 30)
```

Movie Directors: 429, ~~**2931**~~, 11652, 14927, 15092

### Connection to `filter()`

```{r}
#| echo: true
#| eval: false
directors_genres |>
  filter(director_id %in% movies_directors$director_id)
```

```{r}
#| eval: true
#| echo: false
directors_genres_subset |>
  filter(director_id %in% movies_directors_subset$director_id) |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "320px") |> 
  kableExtra::kable_styling(font_size = 30)
```

:::


## Filtering Joins: `anti_join()`

**Removes** observations when their keys are present in **both** datasets, and **only keeps variables from the first dataset**.

:::: {.columns}
::: {.column width="60%"}

![](images/semi1.png)
:::
::: {.column width="15%"}

<br>

::: {.r-fit-text}
&rarr; &emsp;
:::

:::
::: {.column width="25%"}

<br>

![](images/anti2.png)

:::
::::


## Filtering Joins: `anti_join()`

::: panel-tabset

### `anti_join()`

```{r}
#| echo: true
#| eval: false
directors_genres |> 
  anti_join(movies_directors)
```

```{r}
#| eval: true
#| echo: false
anti_join(directors_genres_subset, movies_directors_subset) |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "200px") |> 
  kableExtra::kable_styling(font_size = 30)
```

Movie Directors: ~~429~~, **2931**, ~~11652~~, ~~14927~~, ~~15092~~

### Connection to `filter()`

```{r}
#| echo: true
#| eval: false
directors_genres |>
  filter(!director_id %in% movies_directors$director_id)
```

```{r}
#| eval: true
#| echo: false
directors_genres_subset |>
  filter(!director_id %in% movies_directors_subset$director_id) |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "200px") |> 
  kableExtra::kable_styling(font_size = 30)
```

:::


## [PA 4: Military Spending](https://zoerehnberg.github.io/STAT331-S23/practice_activities/PA4.html)

Today you will be tidying messy data to explore the relationship between countries of the world and military spending.

+ **Due Wednesday, 4/24 at 10:00am**


## To do...

-   **PA 4: Military Spending**
    -   Due Wednesday, 4/24 at 10:00am